# insight_worker.py

from typing import List, Dict
from workers.message_queue import publish_message
from semantic_engine import semantic_cluster, contains_socially_relevant_keyword
from db import get_zipcode_users, get_higher_cohorts, save_insight
from settings import GATING_THRESHOLDS  # % thresholds per cohort level


### ---------------------------
###   Step 1: Receive Candidates
### ---------------------------
def receive_candidates_from_scoring(post_id: str, user_id: str, zipcode: str, candidates: List[str]):
    """
    Entry point: called whenever a post is processed by scoring engine.
    Receives candidate sentences that have already passed the funnel.
    """
    # Store candidates in short-lived storage (Redis / temp DB table)
    store_candidates(zipcode, user_id, candidates)


### ---------------------------
###   Step 2: Periodic Aggregation
### ---------------------------
def run_zipcode_level_aggregation():
    """
    Runs periodically (e.g. every hour) to aggregate candidate assertions
    into zipcode-level insights using semantic clustering.
    """

    # Get all stored candidates for this run
    all_zipcodes = get_all_zipcodes_with_candidates()

    for zipcode in all_zipcodes:
        candidates = load_candidates(zipcode)

        if not candidates:
            continue

        # Step 2a: Semantic clustering â†’ group similar sentences
        clusters = semantic_cluster(candidates)  
        # clusters = { cluster_id: [ {user_id, text}, ... ] }

        # Step 2b: Count unique users per cluster
        insights_for_zip = []
        total_users_in_zip = get_zipcode_user_count(zipcode)

        for cluster_id, entries in clusters.items():
            unique_users = set(e['user_id'] for e in entries)
            user_pct = len(unique_users) / total_users_in_zip

            if user_pct >= GATING_THRESHOLDS['zipcode']:
                insight_text = generate_insight_text(entries)
                insights_for_zip.append({
                    'cohort_level': 'zipcode',
                    'cohort_id': zipcode,
                    'text': insight_text,
                    'user_pct': user_pct
                })

        # Step 2c: Save insights to DB + publish to insights queue
        for insight in insights_for_zip:
            save_insight(insight)
            publish_message('insights', insight)  # Goes into insights slot

    # After processing, clear stored candidates for next cycle
    clear_all_candidates()


### ---------------------------
###   Step 3: Bubble-Up
### ---------------------------
def run_higher_cohort_bubble_up():
    """
    Runs periodically after zipcode-level aggregation.
    Builds higher-level insights from lower-level cohort insights.
    """

    cohort_hierarchy = ['zipcode', 'city', 'district', 'state', 'country']

    for i in range(len(cohort_hierarchy) - 1):
        lower = cohort_hierarchy[i]
        higher = cohort_hierarchy[i + 1]

        # For each higher cohort entity (e.g. each city)
        for higher_id in get_all_cohort_ids(higher):
            lower_cohorts = get_lower_cohorts(higher, higher_id)  
            total_users_higher = get_cohort_user_count(higher, higher_id)

            # Collect all lower-cohort insights for this higher entity
            candidate_pool = []
            for lower_id in lower_cohorts:
                insights = get_recent_insights(lower, lower_id)
                candidate_pool.extend(insights)

            # Cluster semantically
            clusters = semantic_cluster(candidate_pool)  

            for cluster_id, entries in clusters.items():
                unique_users = set(e['user_id'] for e in entries)
                user_pct = len(unique_users) / total_users_higher

                if user_pct >= GATING_THRESHOLDS[higher]:
                    insight_text = generate_insight_text(entries)
                    save_insight({
                        'cohort_level': higher,
                        'cohort_id': higher_id,
                        'text': insight_text,
                        'user_pct': user_pct
                    })
                    publish_message('insights', {
                        'cohort_level': higher,
                        'cohort_id': higher_id,
                        'text': insight_text,
                        'user_pct': user_pct
                    })
